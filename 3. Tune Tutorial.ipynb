{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Tune Tutorial**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/ray-project/tutorial/blob/master/tune_exercises/Tune.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Outline**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0. Preprocess the Data\n",
    "1. Create and train a model on a toy dataset\n",
    "2. Integrating Tune into workflow\n",
    "3. Trying out advanced features\n",
    "4. Validating trained model\n",
    "5. Try out a search algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from IPython.display import HTML\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **PART 0: Preprocess the Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1)\n",
      "(60000, 10)\n",
      "(10000, 28, 28, 1)\n",
      "(10000, 10)\n"
     ]
    }
   ],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "X_train = X_train.reshape(X_train.shape[0], 28, 28, 1).astype('float32')\n",
    "X_test = X_test.reshape(X_test.shape[0], 28, 28, 1).astype('float32')\n",
    "\n",
    "#Preprocess the input\n",
    "mean_img = np.mean(X_train,0)\n",
    "X_train -= mean_img\n",
    "X_test  -= mean_img\n",
    "\n",
    "num_classes = 10\n",
    "y_train = np_utils.to_categorical(y_train, num_classes)\n",
    "y_test = np_utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_batch(X_data, y_data, batch_size):\n",
    "    samples_per_epoch = X_data.shape[0]\n",
    "    number_of_batches = samples_per_epoch//batch_size\n",
    "    global counter\n",
    "\n",
    "    X_batch = np.array(X_data[batch_size*counter:batch_size*(counter+1)]).astype('float32')\n",
    "    y_batch = np.array(y_data[batch_size*counter:batch_size*(counter+1)]).astype('float32')\n",
    "    counter += 1\n",
    "\n",
    "    #restart counter to yeild data in the next epoch as well\n",
    "    if counter >= number_of_batches:\n",
    "        counter = 0\n",
    "    \n",
    "    return X_batch,y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **PART 1: Creating a model to be trained**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "parser = argparse.ArgumentParser(description = 'Keras MNIST Example')\n",
    "parser.add_argument('--epochs', type=int, default = 2, help = 'epoch')\n",
    "parser.add_argument('--batch_size', type=int, default = 128, help = 'batch_size')\n",
    "\n",
    "parser.add_argument('--lr', type=float, default = 0.1, help = 'learning rate')\n",
    "parser.add_argument('--momentum', type = float, default = 0.0, help = 'SGD momentum')\n",
    "parser.add_argument('--kernel1', type = int, default = 3, help = 'Size of first kernel')\n",
    "parser.add_argument('--kernel2', type = int, default = 3, help = 'Size if second kernel')\n",
    "parser.add_argument('--poolsize', type = int, default = 2, help = 'Size of Pooling')\n",
    "parser.add_argument('--dropout1', type = float, default = 0.25, help = 'first kernel dropout rate')\n",
    "parser.add_argument('--dropout2', type = float, default = 0.5, help = 'second kernel dropout rate')\n",
    "parser.add_argument('--hidden', type = int, default = 32, help = 'Size of Hidden Layer')\n",
    "\n",
    "DEFAULT_ARGS = vars(parser.parse_known_args()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 128,\n",
       " 'dropout1': 0.25,\n",
       " 'dropout2': 0.5,\n",
       " 'epochs': 2,\n",
       " 'hidden': 32,\n",
       " 'kernel1': 3,\n",
       " 'kernel2': 3,\n",
       " 'lr': 0.1,\n",
       " 'momentum': 0.0,\n",
       " 'poolsize': 2}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEFAULT_ARGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(parameters):\n",
    "    config = DEFAULT_ARGS.copy()\n",
    "    config.update(parameters)\n",
    "    num_classes = 10\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, kernel_size = (config['kernel1'], config['kernel1']), activation = 'relu', input_shape = (28,28,1)))\n",
    "    model.add(Conv2D(64, kernel_size = (config['kernel2'], config['kernel2']), activation = 'relu'))\n",
    "    model.add(MaxPooling2D(pool_size = (config['poolsize'], config['poolsize'])))\n",
    "    model.add(Dropout(config[\"dropout1\"]))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(config['hidden'], activation = 'relu'))\n",
    "    model.add(Dropout(config[\"dropout2\"]))\n",
    "    model.add(Dense(num_classes, activation = 'softmax'))\n",
    "    \n",
    "    model.compile(loss = keras.losses.categorical_crossentropy, \n",
    "                  optimizer = keras.optimizers.SGD(lr = config[\"lr\"], momentum = config[\"momentum\"]), \n",
    "                  metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_mnist(args, X_train, y_train):\n",
    "    \"\"\"Loads data, and saves the weights\"\"\"\n",
    "    model = make_model(args)\n",
    "    print(model.summary())\n",
    "\n",
    "    batch_size = args['batch_size']\n",
    "    epochs = args['epochs']\n",
    "    \n",
    "    model.fit(X_train, y_train, \n",
    "              batch_size = batch_size,\n",
    "              epochs = epochs,\n",
    "              verbose = 1,\n",
    "              validation_data = (X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 24, 24, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                294944    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                330       \n",
      "=================================================================\n",
      "Total params: 314,090\n",
      "Trainable params: 314,090\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/2\n",
      "60000/60000 [==============================] - 5s 87us/step - loss: 14.2008 - acc: 0.1020 - val_loss: 14.4612 - val_acc: 0.1028\n",
      "Epoch 2/2\n",
      "60000/60000 [==============================] - 4s 72us/step - loss: 13.5993 - acc: 0.1093 - val_loss: 14.4612 - val_acc: 0.1028\n"
     ]
    }
   ],
   "source": [
    "train_mnist(DEFAULT_ARGS, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **PART 2: Setting up Tune**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tune utilizes Ray as a backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-03-27 23:27:59,081\tWARNING worker.py:1406 -- WARNING: Not updating worker name since `setproctitle` is not installed. Install this with `pip install setproctitle` (or ray[debug]) to enable monitoring of worker processes.\n",
      "2019-03-27 23:27:59,082\tINFO node.py:423 -- Process STDOUT and STDERR is being redirected to /tmp/ray/session_2019-03-27_23-27-59_5655/logs.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Not monitoring node memory since `psutil` is not installed. Install this with `pip install psutil` (or ray[debug]) to enable debugging of memory-related crashes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-03-27 23:27:59,208\tINFO services.py:363 -- Waiting for redis server at 127.0.0.1:50575 to respond...\n",
      "2019-03-27 23:27:59,407\tINFO services.py:363 -- Waiting for redis server at 127.0.0.1:34625 to respond...\n",
      "2019-03-27 23:27:59,414\tINFO services.py:760 -- Starting Redis shard with 3.32 GB max memory.\n",
      "2019-03-27 23:27:59,524\tINFO services.py:1384 -- Starting the Plasma object store with 4.98 GB memory using /dev/shm.\n",
      "2019-03-27 23:27:59,591\tWARNING services.py:863 -- Failed to start the reporter. The reporter requires 'pip install psutil'.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'node_ip_address': None,\n",
       " 'object_store_address': '/tmp/ray/session_2019-03-27_23-27-59_5655/sockets/plasma_store',\n",
       " 'raylet_socket_name': '/tmp/ray/session_2019-03-27_23-27-59_5655/sockets/raylet',\n",
       " 'redis_address': '192.168.25.47:50575',\n",
       " 'webui_url': None}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ray\n",
    "from ray import tune\n",
    "\n",
    "ray.init(ignore_reinit_error=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Two steps to use Tune**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1) We need to make a signature to a specific format. Pass a **reporter object** to the below train_mnist_tune class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "def trainable(config, reporter):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        config (dict): Parameters provided from the search algorithm\n",
    "            or variant generation.\n",
    "        reporter (Reporter): Handle to report intermediate metrics to Tune.\n",
    "    \"\"\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 2) We want to keep track of performance as the model is training. <br>\n",
    "e.g. Call the reporter to report the mean accuracy for every batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "\n",
    "def train_func(config, reporter):  # add a reporter arg\n",
    "    # ...\n",
    "    for data, target in dataset:\n",
    "        model.fit(data, target)\n",
    "        save_model()\n",
    "        accuracy = model.evaluate(x_batch, y_batch)[1]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TuneCallback(keras.callbacks.Callback):\n",
    "    def __init__(self, reporter, logs={}):\n",
    "        self.reporter = reporter\n",
    "        self.iteration = 0\n",
    "\n",
    "    def on_train_end(self, epoch, logs={}):\n",
    "        self.reporter(timesteps_total=self.iteration, done=1, mean_accuracy=logs[\"acc\"])\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        self.iteration += 1\n",
    "        self.reporter(timesteps_total=self.iteration, mean_accuracy=logs[\"acc\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_mnist_tune(args, X_train, y_train, reporter):\n",
    "    \"\"\"Loads data, and saves the weights\"\"\"\n",
    "    model = make_model(args)\n",
    "    #print(model.summary())\n",
    "\n",
    "    batch_size = args['batch_size']\n",
    "    epochs = args['epochs']\n",
    "    \n",
    "    model.fit(X_train, y_train, \n",
    "              batch_size = batch_size,\n",
    "              epochs = epochs,\n",
    "              verbose = 1,\n",
    "              validation_data = (X_test, y_test),\n",
    "              callbacks = [TuneCallback(reporter)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ray.tune.schedulers import AsyncHyperBandScheduler\n",
    "from ray import tune\n",
    "\n",
    "scheduler = AsyncHyperBandScheduler(\n",
    "        time_attr=\"timesteps_total\",\n",
    "        reward_attr=\"mean_accuracy\",\n",
    "        max_t=400,\n",
    "        grace_period=20)\n",
    "\n",
    "tune.register_trainable(\n",
    "        \"TRAIN_FN\",\n",
    "        lambda config, reporter: train_mnist_tune(DEFAULT_ARGS, X_train, y_train, reporter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-03-27 23:46:44,583\tINFO tune.py:60 -- Tip: to resume incomplete experiments, pass resume='prompt' or resume=True to run()\n",
      "2019-03-27 23:46:44,584\tINFO tune.py:211 -- Starting a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 180.000: None | Iter 60.000: None | Iter 20.000: None\n",
      "Bracket: Iter 180.000: None | Iter 60.000: None\n",
      "Bracket: Iter 180.000: None\n",
      "Resources requested: 0/12 CPUs, 0/1 GPUs\n",
      "Memory usage on this node: 6.6/16.6 GB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-03-27 23:46:45,493\tERROR worker.py:1780 -- Warning: The actor WrappedFunc has size 222325080 when pickled. It will be stored in Redis, which could cause memory issues. This may mean that its definition uses a large array or other object.\n",
      "2019-03-27 23:46:45,603\tWARNING util.py:62 -- The `start_trial` operation took 0.7504630088806152 seconds to complete, which may be a performance bottleneck.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Status ==\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 180.000: None | Iter 60.000: None | Iter 20.000: None\n",
      "Bracket: Iter 180.000: None | Iter 60.000: None\n",
      "Bracket: Iter 180.000: None\n",
      "Resources requested: 4/12 CPUs, 0.5/1 GPUs\n",
      "Memory usage on this node: 6.9/16.6 GB\n",
      "Result logdir: /home/hojoon/ray_results/exp\n",
      "Number of trials: 1 ({'RUNNING': 1})\n",
      "RUNNING trials:\n",
      " - TRAIN_FN_0_lr=0.060213:\tRUNNING\n",
      "\n",
      "\u001b[2m\u001b[36m(pid=5774)\u001b[0m Using TensorFlow backend.\n",
      "\u001b[2m\u001b[36m(pid=5774)\u001b[0m 2019-03-27 23:46:46.769405: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "\u001b[2m\u001b[36m(pid=5774)\u001b[0m Train on 60000 samples, validate on 10000 samples\n",
      "\u001b[2m\u001b[36m(pid=5774)\u001b[0m Epoch 1/2\n",
      "\u001b[2m\u001b[36m(pid=5774)\u001b[0m 2019-03-27 23:46:46.833682: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:897] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "\u001b[2m\u001b[36m(pid=5774)\u001b[0m 2019-03-27 23:46:46.833981: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1405] Found device 0 with properties: \n",
      "\u001b[2m\u001b[36m(pid=5774)\u001b[0m name: GeForce GTX 1070 major: 6 minor: 1 memoryClockRate(GHz): 1.683\n",
      "\u001b[2m\u001b[36m(pid=5774)\u001b[0m pciBusID: 0000:01:00.0\n",
      "\u001b[2m\u001b[36m(pid=5774)\u001b[0m totalMemory: 7.93GiB freeMemory: 169.88MiB\n",
      "\u001b[2m\u001b[36m(pid=5774)\u001b[0m 2019-03-27 23:46:46.833992: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1484] Adding visible gpu devices: 0\n",
      "\u001b[2m\u001b[36m(pid=5774)\u001b[0m 2019-03-27 23:46:47.006598: I tensorflow/core/common_runtime/gpu/gpu_device.cc:965] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "\u001b[2m\u001b[36m(pid=5774)\u001b[0m 2019-03-27 23:46:47.006624: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971]      0 \n",
      "\u001b[2m\u001b[36m(pid=5774)\u001b[0m 2019-03-27 23:46:47.006629: I tensorflow/core/common_runtime/gpu/gpu_device.cc:984] 0:   N \n",
      "\u001b[2m\u001b[36m(pid=5774)\u001b[0m 2019-03-27 23:46:47.006714: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1097] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 107 MB memory) -> physical GPU (device: 0, name: GeForce GTX 1070, pci bus id: 0000:01:00.0, compute capability: 6.1)\n",
      "\u001b[2m\u001b[36m(pid=5774)\u001b[0m 2019-03-27 23:46:47.007256: E tensorflow/stream_executor/cuda/cuda_driver.cc:903] failed to allocate 107.88M (113115136 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY\n",
      "\u001b[2m\u001b[36m(pid=5774)\u001b[0m 2019-03-27 23:46:47.154613: E tensorflow/stream_executor/cuda/cuda_blas.cc:459] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED\n",
      "\u001b[2m\u001b[36m(pid=5774)\u001b[0m 2019-03-27 23:46:47.156942: E tensorflow/stream_executor/cuda/cuda_blas.cc:459] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED\n",
      "\u001b[2m\u001b[36m(pid=5774)\u001b[0m 2019-03-27 23:46:47.158708: E tensorflow/stream_executor/cuda/cuda_blas.cc:459] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED\n",
      "\u001b[2m\u001b[36m(pid=5774)\u001b[0m 2019-03-27 23:46:47.159763: E tensorflow/stream_executor/cuda/cuda_blas.cc:459] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED\n",
      "\u001b[2m\u001b[36m(pid=5774)\u001b[0m 2019-03-27 23:46:47.161029: E tensorflow/stream_executor/cuda/cuda_blas.cc:459] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-03-27 23:46:47,274\tERROR trial_runner.py:460 -- Error processing event.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/hojoon/anaconda3/envs/tf/lib/python3.5/site-packages/ray/tune/trial_runner.py\", line 409, in _process_trial\n",
      "    result = self.trial_executor.fetch_result(trial)\n",
      "  File \"/home/hojoon/anaconda3/envs/tf/lib/python3.5/site-packages/ray/tune/ray_trial_executor.py\", line 314, in fetch_result\n",
      "    result = ray.get(trial_future[0])\n",
      "  File \"/home/hojoon/anaconda3/envs/tf/lib/python3.5/site-packages/ray/worker.py\", line 2316, in get\n",
      "    raise value\n",
      "ray.exceptions.RayActorError: The actor died unexpectedly before finishing this task.\n",
      "2019-03-27 23:46:47,276\tERROR worker.py:1780 -- A worker died or was killed while executing task 000000004c70be56092e5a6001cf44eab29aea88.\n",
      "2019-03-27 23:46:47,276\tINFO ray_trial_executor.py:178 -- Destroying actor for trial TRAIN_FN_0_lr=0.060213. If your trainable is slow to initialize, consider setting reuse_actors=True to reduce actor creation overheads.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2m\u001b[36m(pid=5774)\u001b[0m 2019-03-27 23:46:47.162168: E tensorflow/stream_executor/cuda/cuda_blas.cc:459] failed to create cublas handle: CUBLAS_STATUS_NOT_INITIALIZED\n",
      "\u001b[2m\u001b[36m(pid=5774)\u001b[0m 2019-03-27 23:46:47.166628: E tensorflow/stream_executor/cuda/cuda_dnn.cc:352] Could not create cudnn handle: CUDNN_STATUS_INTERNAL_ERROR\n",
      "\u001b[2m\u001b[36m(pid=5774)\u001b[0m Fatal Python error: Segmentation fault\n",
      "\u001b[2m\u001b[36m(pid=5774)\u001b[0m \n",
      "== Status ==\n",
      "Using AsyncHyperBand: num_stopped=0\n",
      "Bracket: Iter 180.000: None | Iter 60.000: None | Iter 20.000: None\n",
      "Bracket: Iter 180.000: None | Iter 60.000: None\n",
      "Bracket: Iter 180.000: None\n",
      "Resources requested: 0/12 CPUs, 0.0/1 GPUs\n",
      "Memory usage on this node: 6.8/16.6 GB\n",
      "Result logdir: /home/hojoon/ray_results/exp\n",
      "Number of trials: 1 ({'ERROR': 1})\n",
      "ERROR trials:\n",
      " - TRAIN_FN_0_lr=0.060213:\tERROR, 1 failures: /home/hojoon/ray_results/exp/TRAIN_FN_0_lr=0.060213_2019-03-27_23-46-45e2j0mdpp/error_2019-03-27_23-46-47.txt\n",
      "\n"
     ]
    },
    {
     "ename": "TuneError",
     "evalue": "('Trials did not complete', [TRAIN_FN_0_lr=0.060213])",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTuneError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-27-3989dd4e13a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \"config\": {\n\u001b[1;32m     16\u001b[0m             \"lr\": tune.sample_from(\n\u001b[0;32m---> 17\u001b[0;31m                 lambda spec: np.random.uniform(0.001, 0.1))\n\u001b[0m\u001b[1;32m     18\u001b[0m             \u001b[0;31m#\"momentum\": tune.sample_from(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[0;31m#    lambda spec: np.random.uniform(0.1, 0.9)),\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tf/lib/python3.5/site-packages/ray/tune/tune.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(run_or_experiment, name, stop, config, resources_per_trial, num_samples, local_dir, upload_dir, trial_name_creator, loggers, sync_function, checkpoint_freq, checkpoint_at_end, export_formats, max_failures, restore, search_alg, scheduler, with_server, server_port, verbose, resume, queue_trials, reuse_actors, trial_executor, raise_on_failed_trial)\u001b[0m\n\u001b[1;32m    251\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0merrored_trials\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mraise_on_failed_trial\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mTuneError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Trials did not complete\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrored_trials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Trials did not complete: %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrored_trials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTuneError\u001b[0m: ('Trials did not complete', [TRAIN_FN_0_lr=0.060213])"
     ]
    }
   ],
   "source": [
    "tune.run(\n",
    "    \"TRAIN_FN\",\n",
    "    name=\"exp\",\n",
    "    scheduler=scheduler,\n",
    "    **{\n",
    "        \"stop\": {\n",
    "            \"mean_accuracy\": 0.99,\n",
    "            \"timesteps_total\": 10\n",
    "        },\n",
    "        \"num_samples\": 1,\n",
    "        \"resources_per_trial\": {\n",
    "            \"cpu\": 4,\n",
    "            \"gpu\": 0.5\n",
    "        },\n",
    "        \"config\": {\n",
    "            \"lr\": tune.sample_from(\n",
    "                lambda spec: np.random.uniform(0.001, 0.1))\n",
    "            #\"momentum\": tune.sample_from(\n",
    "            #    lambda spec: np.random.uniform(0.1, 0.9)),\n",
    "            #\"hidden\": tune.sample_from(\n",
    "            #    lambda spec: np.random.randint(32, 512)),\n",
    "            #\"dropout1\": tune.sample_from(\n",
    "            #    lambda spec: np.random.uniform(0.2, 0.8)),\n",
    "        }\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
